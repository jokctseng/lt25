---
title: 專有名詞介紹
description: 先看看一些基本名詞
---

> 審議業師 小工| 2025年編纂



## 核心概念

- **人工智能(AI)**: 一個廣泛的領域，指能模擬人類智慧（如：學習、解決問題和決策）的電腦系統
- **機器學習(ML)**: 人工智慧的一個子集，系統透過數據學習而無需明確設計。演算法會識別模式並做出預測或決策。範例包括：
    * **監督式學習 (Supervised Learning):** 在標記數據（輸入-輸出對）上訓練模型，以預測新、未見數據的結果。例如：垃圾郵件檢測，電子郵件被標記為「垃圾郵件」或「非垃圾郵件」。
    * **非監督式學習 (Unsupervised Learning):** 在未標記的數據中發現隱藏的模式或結構。例如：對相似的客戶行為進行分群。
    * **強化學習 (Reinforcement Learning):** 透過獎勵期望的行為並懲罰不期望的行為，訓練一個代理程式在環境中做出最佳決策。通常用於機器人和遊戲。
* **深度學習 (Deep Learning, DL):** 機器學習的一個子領域，使用具有多層（因此稱為「深度」）的人工神經網路來分析複雜的數據，如：圖像、音訊和自然語言。
* **自然語言處理 (Natural Language Processing, NLP):** 專注於使電腦能夠理解、解釋和生成人類語言的領域，常用於聊天機器人和語言翻譯工具。
* **電腦視覺 (Computer Vision):** 一個使電腦能夠從圖像和影片中「看」和解釋資訊的領域，用於人臉識別和自動駕駛汽車。
* **演算法 (Algorithm):** 一組用於解決問題或執行任務的明確定義的指令。人工智慧模型建立在各種演算法之上。
* **可解釋人工智慧 (Explainable AI, XAI):** 使人工智慧模型的決策和推理過程對人類透明且可理解的技術。這對於建立信任和責任至關重要。
* **大型語言模型 (Large Language Models, LLMs):** 這是一種基於深度學習的 AI 模型，經過對大量文本數據的訓練，使其能夠理解、生成和處理人類語言。LLMs 能夠執行各種自然語言處理任務，例如：文本生成、翻譯、問答和摘要。
* **生成式人工智慧 (Generative AI, GenAI):** 這是一類 AI 模型，主要目的是創建新的內容，例如：文本、圖像、影片或程式碼等。LLMs 是生成式 AI 的一種，專注於生成文本。其他的 GenAI 模型可以生成圖像（例如 Stable Diffusion、DALL-E）、音樂、甚至蛋白質結構。




## 常見技術相關名詞


* **檢索增強生成 (Retrieval-Augmented Generation, RAG):** 結合資訊檢索和文本生成的方法。當 LLM 需要回答問題或生成與特定主題相關的文本時，RAG 首先從一個大型的外部知識庫中檢索相關的文件或段落，然後將這些檢索到的資訊作為輸入的一部分，指導 LLM 生成更準確、更具事實依據且更符合上下文的答案或內容，有助於克服 LLM 本身知識的局限性，並減少產生幻覺的可能性。
* **微調 (Fine-tuning):** 一種遷移學習的技術，在一個已經預訓練好的大型模型（例如：一個通用的 LLM）的基礎上，使用一個較小、更特定的數據集進行額外的訓練。這個過程調整了模型原有的權重參數，使其更擅長執行特定的下游任務或適應特定的領域或風格。例如：一個在通用文本數據上預訓練的 LLM 可以通過在醫學文獻上進行微調，使其更擅長回答醫療相關的問題。
* **Transformer:** 這是一種在深度學習中被廣泛使用的神經網路架構，尤其是在自然語言處理領域。Transformer 架構的核心機制是「自注意力 (Self-Attention)」，它允許模型在處理序列數據（例如：句子中的單詞）時，同時考慮到序列中不同位置的元素之間的關係。Transformer 架構由於其並行處理能力和捕捉長距離依賴關係的能力，已經成為構建最先進的 LLMs 和許多其他序列模型的基礎。它取代了之前常用的循環神經網路 (RNN) 及其變體 (如 LSTM、GRU)。
* **思維鏈 (Chain-of-Thought, CoT):** 提升大型語言模型 (LLMs) 在複雜推理任務上表現的技術。CoT 的核心是引導模型**逐步思考問題的解決過程**，就像人類解決複雜問題時會一步步地展示其思考路徑一樣。通過在訓練或提示 階段提供中間的推理步驟範例，模型學會生成這些逐步的思考過程，最終導向正確的答案。CoT 有助於模型分解複雜問題、進行多步推理，並提高答案的可解釋性。
* **提示工程 (Prompt Engineering):** 提示 (Prompt) 是提供給 LLM 的輸入文本，用於指示模型生成特定的輸出。提示工程是指設計和優化這些輸入提示的藝術和科學，以引導模型產生期望的、高質量的結果。有效的提示可以包括明確的指令、上下文資訊、輸入範例、輸出格式要求等。針對不同的任務和模型，需要設計不同的提示策略，例如使用零樣本提示 (Zero-shot Prompting)、少樣本提示 (Few-shot Prompting) 或結合 CoT 等技術。
* **模型蒸餾 (Model Distillation):** 一種模型壓縮技術，將一個大型、複雜的「教師模型」的知識轉移到一個更小、更高效的模「學生模型」中。學生模型通常具有較少的參數和較快的推理速度，更適合在資源受限的環境中部署。蒸餾的過程通常涉及讓學生模型學習模仿教師模型的輸出和行為，而不僅僅是學習原始的訓練數據。
* **模型量化 (Model Quantization):** 一種模型壓縮技術，通過減少模型中權重和激活值的精度（例如從 32 位浮點數降低到 16 位或 8 位整數）來減小模型的大小並提高推理速度。量化可能會帶來一定的精度損失，但通過仔細的量化策略和後訓練調整，可以在保持可接受的性能下降的情況下實現顯著的效率提升。
* **注意力機制 (Attention Mechanism):** Transformer 架構的核心。注意力機制允許模型在處理輸入序列的每個位置時，權重關注序列中的其他相關位置。對於自然語言處理來說，這意味模型可以識別句子中不同單詞之間的依賴關係。自注意力 是指在同一輸入序列的不同位置之間計算注意力，而交叉注意力 (Cross-Attention) 則用於在不同的序列（例如：在翻譯任務中，源語言和目標語言的序列）之間計算注意力。
* **模型污染 (Model Poisoning):** 這是一種針對模型訓練階段的攻擊。攻擊者通過將惡意或有偏見的數據注入到訓練集中，來影響模型的行為。一旦模型被污染，它可能會在特定的輸入下產生錯誤的、有害的或偏向性的輸出，而這些行為可能難以被察覺。模型污染的目標可能是降低模型的整體性能，或者使其在特定的情境下失效，甚至被用於惡意目的。例如，在自動駕駛系統中，被污染的模型可能無法正確識別交通標誌。
* **對抗性攻擊輸入 (Adversarial Attacks):** 針對已部署模型攻擊，攻擊者通過在正常的輸入數據中添加精心設計的、微小且人眼難以察覺的擾動，來欺騙模型產生錯誤的輸出。這些擾動可以導致模型以輸出完全錯誤的結果。對抗性攻擊在圖像識別、自然語言處理、語音識別等多個領域都已得到驗證。例如：在圖像識別中，一個被輕微修改的圖像可能被人類正確識別為貓，但卻被 AI 模型錯誤地分類為狗。
    * **白盒攻擊 (White-box Attacks):** 攻擊者完全了解模型的架構、參數和訓練數據，從而能設計更精密的對抗性擾動。
    * **黑盒攻擊 (Black-box Attacks):** 攻擊者對模型的內部結構一無所知，只能通過查詢模型的輸出並分析其響應來嘗試生成對抗性輸入。
* **模型竊取 (Model Stealing):** 攻擊者的目標是複製或重建一個受保護的、有價值的 AI 模型，可能透過多次查詢模型並分析其輸出，來推斷模型的架構和參數。一旦模型被竊取，攻擊者可以未經授權使用該模型，或者利用其漏洞進行進一步的攻擊。
* **後門攻擊 (Backdoor Attacks):** 攻擊者在訓練過程中向模型注入特定的「觸發器」。當輸入中包含這些觸發器時（例如：圖像中的一個特定圖案，或文本中的一個不常見的詞組），模型會產生預先設定的錯誤輸出，而在正常的輸入下，模型的行為看起來是正常的。後門攻擊難以檢測，因為只有在觸發條件滿足時才會顯現出來。




---

???+ question "想一想"
	- 不同AI技術可能帶來哪些不同的價值與風險？
	- AI的特色是什麼，為什麼我們需要特別討論它？
	- 所設定的議題有特別局限的技術還是探討廣義AI？