---
title: 各國規範發展
description: 看看國際怎麼做
---

> 審議業師 小工｜2025年編纂

---

!!! warning "提醒"

	- 部分法規美國多州皆有制定但僅簡列其中數州，對該範疇有興趣可再擴大搜索
	- 涉及美國的相關文件、法規需留意在今年1/20後是否持續或已被調整、暫停


## 規範與指引
??? note "歐盟人工智慧法案"
	- [EU AI Act](https://artificialintelligenceact.eu/)基於風險控管制定，根據人工智慧帶來的風險差異應用不同的規則
	- 重要規定如下：
    	- 禁止某些被認為帶來不可接受風險的人工智慧應用場景，如：
        	- 社會評分系統（根據個人的社會行為對個人進行評估或分類的系統）
        	- 職場和教育機構中的情緒識別系統（例外：基於醫療或安全目的的）
        	- 被用來利用人們的弱點
        	- 無差別從網路或監視器抓取臉部影像用於臉部辨識資料庫
        	- 根據敏感特徵識別個人的生物辨識系統
        	- 具體的預測警務應用
        	- 執法部門在公共場所使用即時遠端生物特徵識別系統（除非有例外情況，通常需要獲得司法或獨立行政機關的預授權）。
    	- 開發和部署高風險人工智慧的標準
    	- 通用人工智慧 (GPAI) 模型的規則
    - 一些後續相關的準則與規範
        - 通用人工智慧實踐守則（草案）
        - 關於禁止的人工智慧行為指引

??? note "美國SR-11-7"
	- [SR-11-7](https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm)針對銀行業的模型治理監管標準。
	- 要求銀行在全公司範圍內落實模型風險管理措施，並更新已實施、正開發或最近淘汰的模型清單。
	- 機構須證明模型正實現他們想要解決的業務目標，且這些模型是最新的、沒有偏離方向。
	- 模型開發和驗證必須使任何不熟悉模型的人都能理解模型的操作、侷限和關鍵假設。

??? note "加拿大自動化決策準則(Directive)"
	- [加拿大自動化決策準則](https://www.tbs-sct.canada.ca/pol/doc-eng.aspx?id=32592)說明如何使用AI來指導多個政府部門的行政決策
	- 使用評分系統評估提供公民服務的AI工具所需的介入、同儕審查、監控和應急計畫
	- 擁有分數高的人工智慧工具的組織需要進行兩次獨立的同儕審查，並發布簡單易懂的公告，制定人為介入安全措施，並未系統建立定期培訓。

??? note "新加坡人工智慧系統安全指南"
	- [新加坡人工智慧系統安全指南](https://www.csa.gov.sg/resources/publications/guidelines-and-companion-guide-on-securing-ai-systems)目標是強化AI系統安全，有效預防供應鏈攻擊、對抗式機器學習攻擊等安全風險，協助組織以安全方式運用AI，確保AI系統的整體安全與穩定
	- 指南中將AI系統生命週期分成五個關鍵階段，並就各階段安全風險提出相關措施：
    	- 規劃與設計：提升AI安全風險認知能力，進行安全風險評估。
    	- 開發：提升訓練資料、模型、應用程式介面與軟體庫之供應安全，確保供應商遵守安全政策與國際標準或進行風險管理；辨識、追蹤及保護AI相關資產（例如：模型、資料、輸入指令），以確保AI開發環境安全。
    	- 部署：適用標準安全措施（例如：權限控制、日誌記錄），並建立事件管理程序。
    	- 運作與維護：持續監控AI系統的輸入和輸出，偵測異常與潛在攻擊，並建立漏洞揭露流程。
    	- 壽命終期：應根據相關行業標準或法規，對資料與模型進行適當之處理、銷毀，防止未經授權之存取。

??? note "中國生成式人工智能服務管理暫行辦法"
	- 提供和使用生成式人工智慧服務必須遵守的規範
	- 提及之不得侵害的權益為著作權（原條文用詞：知識產權）、身心健康、肖像權、名譽權、榮譽全、隱私權和個資權益（原條文用詞：個人信息）
	- 演算法採取避免歧視措施；提升生成式AI透明度並提高產製内容的準確度及可信度

??? note "日本人工智慧著作權檢核清單和指引"
	- [日本人工智慧著作權檢核清單和指引](https://www.bunka.go.jp/seisaku/bunkashingikai/chosakuken/seisaku/r06_02/pdf/94089701_05.pdf)由文化廳為降低著作權風險並保護著作權人權利制定發佈
	- 主要分為人工智慧開發、提供和使用清單以及著作權人權益保護
	- 針對開發者、提供者以及使用者提醒應注意的侵權風險極可能的合理使用範圍
	- [新動態｜2025-02：內閣會議敲定AI新法案，依法對AI風險進行調查，並提供企業指引與建議](https://tchina.kyodonews.net/news/2025/02/bdb69ccd10a2-ai-.html)；設立由首相領導的新組織「AI戰略總部」，全體閣員都是成員，將研擬並制定AI基本計畫，擴大研發投資；政府將與企業及地方政府合作，推動專業人才，並積極參與制定國際規則。

??? note "韓國人工智慧基本法"
	- [韓國人工智慧基本法](https://www.shinkim.com/kor/media/newsletter/2666)預計2026年1月開始正式實施
	- 重點放在治理機制、培養產業、預防風險：建立國家人工智慧委員會和人工智慧安全研究所等推進AI相關政策的組織單位；制定相關政策，推動研發、資料中心等產業發展；建構高風險AI和生成式AI的安全與可信基礎，減少對社會的影響。

??? note "印度人工智慧能力架構(Competency Framework)"
	- [印度人工智慧能力架構](https://indiaai.gov.in/article/empowering-public-sector-leadership-a-competency-framework-for-ai-integration-in-india)今年三月初發布
	- 目標和主要內容是確保公部門能夠充分利用人工智慧促進行政措施的創新、效率與有倫理的人工智慧治理，要點簡列如下：
    	- 提供對人工智慧的基礎理解，包括其核心功能和限制
    	- 定義公共部門所需的行為、職能和特定領域能力
    	- 增強認識新興人工智慧技術及其對政府服務的影響
    	- 尋找整合人工智慧的機會以提高效率和服務
    	- 落實知情的(informed)政策制定和監管監督
    	- 制定培訓和能力建設計畫
    	- 建立政府職位職涯發展和結構化的績效評估方法。

??? note "澳洲負責任使用人工智慧之政策"
	- [澳洲負責任使用人工智慧之政策](https://www.digital.gov.au/policy/ai/policy)2024年9月生效。
	- 目標為透過提升透明度、風險評估，增進人民對政府應用AI的信任
	- 主要針對非企業的聯邦個體，但也鼓勵企業可使用
	- 公布透明度聲明：各機構應在政策生效起6個月內（即2025年2月28日前）公開發布透明度聲明，概述其應用AI的方式。
	- 提交當責人員（accountable official，下稱AO）名單，當責人員的職責範圍簡列如下：
    	- 制定並管考AI治理機制：制定、調整機構採取的AI治理機制，並定期管考落實情況向DTA回報；鼓勵所有職員執行AI基礎知能訓練，依循業務範圍進行額外培訓，讓機構內的利害關係人明白政策的影響
    	- 評估風險並就高風險AI提供說明：當既有AI 應用案例被機構評估為高風險AI應用案例時，通知DTA該機構所認定之高風險AI應用案例，資訊應包括：AI的類型、預期的應用、評估為高風險的原因、是否有任何敏感性資訊（any sensitivities）
    	- 擔任協調AI的聯絡窗口

---

## 國家策略

??? danger "新加坡"
	- 主要策略：新加坡國家AI策略2.0（2023）
	- 背景：新加坡是世界上第一個擁有「數位孿生」的國家（可以想成就是新加坡的虛擬模型）
	- 目標
    	- 卓越(excellence)：選擇性開發人工智慧領域的卓越成果，以推動該領域的發展並最大限度創造價值，引導人工智慧解決時代的需求和挑戰，例如：人口健康和氣候變遷等具有全球重要性的領域。
    	- 賦權(empowerment)：鼓勵個人、企業和社區自信、明智、信任地使用人工智慧。希望人工智慧成為偉大等化器，為人民和企業提供能力和資源，使其能在人工智慧的未來蓬勃發展。
	- 3個系統＋10個推動要素
	![ ](https://www.smartnation.gov.sg/images/initiatives/Nais/nais_2_0_plan.png) 
	- 15個行動
	- [詳見手冊](https://file.go.gov.sg/nais2023.pdf)
	- [參考影片](https://youtu.be/6qHBTi3YQIQ)
??? danger "韓國"
	- 主要策略：[AI創新戰略](https://www.korea.kr/briefing/pressReleaseView.do?newsId=156652417)
	- 目標：2030年躋身全球AI前三名
	- AI人才政策：2023年韓國AI人才數約5.1萬名，目標是2030年20萬名AI人才，因此透過**基於數據的科技人才政策深化戰略**擬發展人才政策與提供支持。其以**數據分析**為基礎，掌握科技人才需求並追蹤理工碩、博士的發展，建立涵蓋12項國家戰略技術領域的**人才地圖**，以期強化產學合作並緩解人才供需失衡，提升研發投資效率。
??? danger "烏拉圭"
	- 主要策略：[國家人工智慧戰略](https://www.gub.uy/agencia-gobierno-electronico-sociedad-informacion-conocimiento/comunicacion/noticias/se-aprobo-estrategia-nacional-inteligencia-artificial-2024-2030)
	- 目標：提高國家公共政策的水準，以發展為基礎——看重AI作為全面可持續發展工具的潛力，同時為經濟增長、國家環境永續、安全和公共管理作出貢獻。具體目標如下。
    	- 政府：建立保證AI發展和使用法律的政府典範，提供可靠的制度保障、明確的監管規則和有效的程序，促進透明度、安全性、包容性和法律保障。
    	- 能力：發展促進資訊架構創新和應用所需的能力和國家條件，同時專注於基礎設施、資料、人才管理和技能。
    	- 永續發展：支持推動包容性經濟成長的動力，促進國家的永續發展，加強私部門的競爭力，促進烏拉圭數位轉型進程，提高管理和公共服務能力，並增強研究和創新能力。最大化這項技術對社會的益處，並減輕可能的負面影響。
	- 產生過程：來自不同學科和領域300 多人的參與，參考來自 40 個州立機構、11 個民間組織、45 個私營部門、學術界和各種利害關係人的回饋。
	- 推動企業的發展和使用道德、負責任、安全、批判、創造性和創新，造福個人和社會所有部門

---

## 各議題相關

### 隱私權/個資

??? example "美國明尼蘇達州制定消費者個人資料保護法"
	- [美國明尼蘇達州制定消費者個人資料保護法](https://www.revisor.mn.gov/bills/bill.php?b=house&f=hf4757&ssn=0&y=2024)預計7/31生效
	- 明尼蘇達州內的企業、高等教育機構、非營利組職均為適用對象，唯高教機構及NPO於2025年7月31起方適用
	- 賦予居民對個資的基本權利，強調不應因行使權利受歧視。包含近用權、修正權、刪除權、請求複本及選擇退出權
	- 企業須盡告知義務、透明化、資料最小化並提供安全維護措施，此外尚須依法回應當事人的請求並保存所有申覆紀錄至少24個月
	- 企業須建立並採取合規政策，包含有主要負責人，如：首席隱私長（Chief Privacy Officer）

### 就業與產業
??? example "美國勞動部人工智慧及勞工福祉文件"
	- 文件全名：人工智慧及勞工福祉：開發人員與雇主的原則暨最佳實務
	- 未開發者及雇主制定使用AI技術開展業務的路線，並確保勞工可從AI創造的新機會中受益並免受潛在危害
	- 基於八項原則提出實踐方式，重點如下：
    	- 賦權勞工：秉持賦權精神，將勞工經驗與意見納入整個週期各環節的活動中
    	- 合乎倫理的方式開發：應為AI系統建立標準，以利進行AI影響評估與稽核，保障勞工安全與權益，確保AI性能符合預期
    	- AI治理和人類監督：應有明確治理計畫，包括對AI的人類監督制度及定期評估流程
    	- 使用透明：雇主應事先告知員工或求職者關於AI的使用、使用目的與可能影響，雇主與開發者共同確保以清晰好懂的方式公開說明AI如何搜集、儲存跟使用勞工個資
   	 	- 保護勞工及就業權利：使用AI時除了要保障其健康安全，也不得侵犯或損害勞工的組織權、法定工資和工時等相關權利
    	- 使用AI增能勞工：雇主應該先了解AI如何協助勞工提高工作品質及其所需技能、工作機會和風險，再決定採用AI
    	- 支援受AI影響的勞工：應為受AI影響的勞工提供技能或其他職能培訓，必要時提供組織內其他的工作機會
    	- 負責任使用個資：開發者及雇主應盡責保護及處理AI所蒐集和使用的勞工個資

??? example "美國伊利諾州人權法修正案"
	- [修正案內容](https://www.lexology.com/library/detail.aspx?g=dfebd021-1398-41eb-92ee-9631183fa8ce)
	- 預計2026年1月1日生效；規範重點為解決人工智慧導入就業市場衍生的就業歧視議題
	- 增加人工智慧與生成式AI法律定義
	- 增加雇主不得因使用AI導致員工權利受侵害之規定
	- 雇主有主動通知員工使用AI工具情形之義務
	- 除了對雇主開罰，也賦予當事人申訴管道

??? example "金融穩定委員會對AI提出風險與建議"
	- [報告內容](https://www.fsb.org/uploads/P14112024.pdf)
	- AI的好處：提升效率、加強法規遵循、提供個人化金融產品及進階資料分析
	- AI構成的金融穩定風險：加劇某些金融部門的脆弱性，包含：第三方依賴及服務供應商集中化、市場相關性、資安風險及模型風險、資料品質和治理
	- 廣泛應用AI導致模型風險上升，且模型的複雜性與透明性不足，增加尋找具獨立性、專業知識的驗證者的挑戰
	- LLM大規模非結構化資料的使用來源不透明，資料品質評估困難，尤其在預訓練模型中
	- 金融機構對眾多資料來源評估方式不熟悉，增加管理難度
	- 呼籲各國金融主管機關加強對AI發展的監測，評估金融政策框架是否充分，增強監管能力；也可利用監督科技與監管科技等AI驅動工具強化監管效能，應對AI帶來的挑戰與風險
	- 建議調查AI應用情形，並透過報告及資訊公開制度獲取相關資訊

### 著作權

??? example "OECD｜抓取資料訓練AI衍生之智慧財產問題"
	- [報告內容](https://www.oecd.org/en/publications/intellectual-property-issues-in-artificial-intelligence-trained-on-scraped-data_d5241a23-en.html)
	- OECD定義：透過自動化的方式從第三方網站、資料庫或社群平台提取資訊
	- 未經同意或未支付相應報酬的抓取行為可能侵害創作者與權利人的著作權、資料庫全等權利
	- 政策建議
    	- 訂定自願性資料抓取行為準則
    	- 提供標準化技術工具
    	- 使用標準化契約條款
    	- 提升法律意識與教育

??? example "美國著作權局AI著作權報告Part 2可受著作權保護性"
	- [報告內容](https://www.copyright.gov/ai/Copyright-and-Artificial-Intelligence-Part-2-Copyrightability-Report.pdf)
	- 現有法律（此指美國）有足夠彈性且可根據個案判斷人為貢獻是否足夠，並不需修法；既有法律也足以鼓勵AI發展，無需為AI產製內容提供額外著作權或特殊權利保護
	- 著作權保護仍以人為創意投入為主，AI僅作為工具且人類能夠決定作品表達元素，對生成結果的選擇、協調或安排以及對結果進行修改，都可獲得著作權保護。
	- 是否使用工具並非重點：Feist Publications, Inc. v. Rural Telephone Service Co.案中，法院否定主張憑藉血汗就足以獲得著作權保障，但同時認為絕大多數作品容易達標，因為所需的創造力水準極低，即便原創性小、粗糙或顯而易見都無妨；在Burrow-Giles Lithographic Co. v. Sarony暗中法院的見解也已說明當作品已包涵足夠人類創作表達元素時使用機器作為工具並不會否定著作權，因此重點不在是否使用工具而是有無投入創造性。
	- 作者的定義：在Community for Creative Non-violence v. Reid, “CCNV”案中認為僅是委託並提供詳細的建議與指示之貢獻並不足以成為共同作者；在Andrien v. Southern Ocean County Chamber of Commerce案中則因原告明確指示準備工作的具體細節使編譯只需簡單轉錄即可實現最終形式且印刷商沒有實質改變原告的原始表達而裁定原告可定義為作者，由此人工智慧產製內容不可視為使用者與AI的共同作品，而僅向AI描述委託作品應該做什麼或看起來像什麼的人，也不能是為著作權法意義上的共同作者
	- 需進一步分析下列使用方式之異同：提供prompts、在AI產製內容中感知到表達性輸入、對AI產製內容進行修改與編排
    	- 所謂表達性輸入，是指使用者輸入自己受著作權保護的作品，若該作品在產生的內容中是可察覺的，那麼該名使用者至少是該部分生成內容的作者；此類AI產製的著作權將涵蓋可察覺的人類表達，包括作者對作品素材的選擇、協調與編排。
    	- 部分AI工具允許使用者使用提示指定產生圖像的區域，此類可讓使用者控制各創意元素的選擇、放置與修改，是否達到最低原創性標準將取決於具體個案情況，但就產製的內容位置可控制的情況，與純粹prompts 情況不同，內容應受著作權保護

??? example "英國著作權法修法"
	- 修法方向：讓公開發表的素材都可被拿來訓練AI模型，不過也有保留權利人不同意時可以**退出**的機制以及探討權利人**被補償的地位**。
	- OpenAI與Google的反應：反對

### 其他
??? example "世界經濟論壇｜生成式AI時代的治理"
	- [白皮書內容](https://www.google.com/url?q=https://www3.weforum.org/docs/WEF_Governance_in_the_Age_of_Generative_AI_2024.pdf&sa=D&source=docs&ust=1745845441483686&usg=AOvVaw3oEHk2aT7b58Jf6Iq7l_s_)
	- 報告提出一個 360度的框架
	- 借鑒過往的監管經驗，促進當前的多方利害關係人參與和知識共享，為未來的技術發展和潛在風險做好準備
		* 促進整個社會參與生成式人工智慧的治理
			* 產業對於在商業應用和公共服務的案中負責任管理生成式AI很重要
			* 政府需要仔細考慮如何避免過度監管和監管不足，以培育蓬勃發展且負責任的AI網絡，透過財政獎勵、明確的法規及針對產業複雜性量身定做的介入措施等方式鼓勵產業主動採取負責任的AI實踐；政策制定者也應確保公民社會組織的充分參與，提供必要的資源和工具，並重視其社群驅動的見解；政策制定者應解決學術利害關係人面臨的一系列挑戰，確保獲得所需的基礎設施、提供研究經費以及縮小產業與學術界之間的薪資差距，以培育蓬勃發展的AI生態系統
			* 公民組織憑藉對生成式AI如何影響其代表的不同社群和議題領域的專業知識，有助於制定知情且全面的政策。然而，CSOs面臨著評估生成式人工智慧技術的社會影響、為治理政策和供應鏈責任提供資訊，以及倡導公民群體和弱勢群體（如兒童）權利的重大存取和參與挑戰。
			* 學術界透過嚴謹獨立的研究和教育倡議，塑造負責任的AI開發和部署以及確保公眾對負責任使用的認知。然而，由於生成式人工智慧需要廣泛且昂貴的基礎設施（如：計算能力、資料），學術界進行領先研究的能力可能受到限制。
		* 政府以身作則，採納負責任的AI實踐
	- 目標：在全球範圍內實現更協調一致的生成式AI治理

??? example "產業：趨勢科技｜AI 世代的網路犯罪趨勢與資安防禦革命"
	- [簡報](https://drive.google.com/file/d/1DIiUNMWlfYVxbV2QB-BrhpX0VSLBy2cO/view?usp=sharing)
	
---
[^1]: 請以各國官方最新狀態為準